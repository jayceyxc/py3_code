{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit5da62c7ed731412fa3edffa85776323d",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 那些功能逆天，却鲜为人知的 pandas 骚操作\n",
    "[链接](https://mp.weixin.qq.com/s/hUSWszONjdhv9jmmM0zDgQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACCESSOR\n",
    "pandas有一种功能非常强大的方法，它就是accessor，可以将它理解为一种属性接口，通过它可以获得额外的方法。其实这样说还是很笼统，下面我们通过代码和实例来理解一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'cat', 'dt', 'sparse', 'str'}"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pd.Series._accessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Series数据结构使用_accessors方法，可以得到了3个对象：cat，str，dt。\n",
    "\n",
    "- .cat：用于分类数据（Categorical data）\n",
    "- .str：用于字符数据（String Object data）\n",
    "- .dt：用于时间数据（datetime-like data）\n",
    "- .sparse：原文没有，待探索\n",
    "\n",
    "下面我们依次看一下这四个对象是如何使用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### str对象的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series数据类型：str字符串\n",
    "addr = pd.Series([\n",
    "     'Washington, D.C. 20003',\n",
    "     'Brooklyn, NY 11211-1755',\n",
    "     'Omaha, NE 68154',\n",
    "     'Pittsburgh, PA 15211'\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     WASHINGTON, D.C. 20003\n1    BROOKLYN, NY 11211-1755\n2            OMAHA, NE 68154\n3       PITTSBURGH, PA 15211\ndtype: object"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "addr.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     washington, d.c. 20003\n1    brooklyn, ny 11211-1755\n2            omaha, ne 68154\n3       pittsburgh, pa 15211\ndtype: object"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "addr.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    5\n1    9\n2    5\n3    5\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "addr.str.count(r'\\d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于以上str对象的2个方法说明：\n",
    "- Series.str.upper：将Series中所有字符串变为大写\n",
    "- Series.str.count：对Series中所有字符串的个数进行计数\n",
    "\n",
    "其实不难发现，该用法的使用与Python中字符串的操作很相似。没错，在pandas中你一样可以这样简单的操作，而不同的是你操作的是一整列的字符串数据。仍然基于以上数据集，再看它的另一个操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = (r'(?P<city>[A-Za-z ]+), '      # 一个或更多字母\n",
    "         r'(?P<state>[A-Z]{2}) '        # 两个大写字母\n",
    "         r'(?P<zip>\\d{5}(?:-\\d{4})?)')  # 可选的4个延伸数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         city state         zip\n0  Washington    DC       20003\n1    Brooklyn    NY  11211-1755\n2       Omaha    NE       68154\n3  Pittsburgh    PA       15211",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>state</th>\n      <th>zip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Washington</td>\n      <td>DC</td>\n      <td>20003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Brooklyn</td>\n      <td>NY</td>\n      <td>11211-1755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Omaha</td>\n      <td>NE</td>\n      <td>68154</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pittsburgh</td>\n      <td>PA</td>\n      <td>15211</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "addr.str.replace('.', '').str.extract(regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于以上str对象的2个方法说明：\n",
    "- Series.str.replace：将Series中指定字符串替换\n",
    "- Series.str.extract：通过正则表达式提取字符串中的数据信息\n",
    "\n",
    "这个用法就有点复杂了，因为很明显看到，这是一个链式的用法。通过replace将 \" . \" 替换为\"\"，即为空，紧接着又使用了3个正则表达式（分别对应city，state，zip）通过extract对数据进行了提取，并由原来的Series数据结构变为了DataFrame数据结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['capitalize',\n 'casefold',\n 'cat',\n 'center',\n 'contains',\n 'count',\n 'decode',\n 'encode',\n 'endswith',\n 'extract',\n 'extractall',\n 'find',\n 'findall',\n 'get',\n 'get_dummies',\n 'index',\n 'isalnum',\n 'isalpha',\n 'isdecimal',\n 'isdigit',\n 'islower',\n 'isnumeric',\n 'isspace',\n 'istitle',\n 'isupper',\n 'join',\n 'len',\n 'ljust',\n 'lower',\n 'lstrip',\n 'match',\n 'normalize',\n 'pad',\n 'partition',\n 'repeat',\n 'replace',\n 'rfind',\n 'rindex',\n 'rjust',\n 'rpartition',\n 'rsplit',\n 'rstrip',\n 'slice',\n 'slice_replace',\n 'split',\n 'startswith',\n 'strip',\n 'swapcase',\n 'title',\n 'translate',\n 'upper',\n 'wrap',\n 'zfill']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 当然，除了以上用法外，常用的属性和方法还有.rstrip，.contains，split等，我们通过下面代码查看一下str属性的完整列表：\n",
    "[i for i in dir(pd.Series.str) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt对象的使用\n",
    "Series数据类型：datetime\n",
    "\n",
    "因为数据需要datetime类型，所以下面使用pandas的date_range()生成了一组日期datetime演示如何进行dt对象操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterng = pd.Series(pd.date_range('2017', periods=9, freq='Q'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0   2017-03-31\n1   2017-06-30\n2   2017-09-30\n3   2017-12-31\n4   2018-03-31\n5   2018-06-30\n6   2018-09-30\n7   2018-12-31\n8   2019-03-31\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "daterng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "daterng = pd.Series(pd.date_range('2017', periods=40, freq='5D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    2017-01-01\n1    2017-01-06\n2    2017-01-11\n3    2017-01-16\n4    2017-01-21\n5    2017-01-26\n6    2017-01-31\n7    2017-02-05\n8    2017-02-10\n9    2017-02-15\n10   2017-02-20\n11   2017-02-25\n12   2017-03-02\n13   2017-03-07\n14   2017-03-12\n15   2017-03-17\n16   2017-03-22\n17   2017-03-27\n18   2017-04-01\n19   2017-04-06\n20   2017-04-11\n21   2017-04-16\n22   2017-04-21\n23   2017-04-26\n24   2017-05-01\n25   2017-05-06\n26   2017-05-11\n27   2017-05-16\n28   2017-05-21\n29   2017-05-26\n30   2017-05-31\n31   2017-06-05\n32   2017-06-10\n33   2017-06-15\n34   2017-06-20\n35   2017-06-25\n36   2017-06-30\n37   2017-07-05\n38   2017-07-10\n39   2017-07-15\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "daterng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      Friday\n1      Friday\n2    Saturday\n3      Sunday\n4    Saturday\n5    Saturday\n6      Sunday\n7      Monday\n8      Sunday\ndtype: object"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "daterng.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2   2017-09-30\n3   2017-12-31\n6   2018-09-30\n7   2018-12-31\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# 查看下半年\n",
    "daterng[daterng.dt.quarter > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3   2017-12-31\n7   2018-12-31\ndtype: datetime64[ns]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "daterng[daterng.dt.is_year_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上关于dt的3种方法说明：\n",
    "- Series.dt.day_name()：从日期判断出所处星期数\n",
    "- Series.dt.quarter：从日期判断所处季节\n",
    "- Series.dt.is_year_end：从日期判断是否处在年底\n",
    "其它方法也都是基于datetime的一些变换，并通过变换来查看具体微观或者宏观日期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['asfreq',\n 'ceil',\n 'components',\n 'date',\n 'day',\n 'day_name',\n 'dayofweek',\n 'dayofyear',\n 'days',\n 'days_in_month',\n 'daysinmonth',\n 'end_time',\n 'floor',\n 'freq',\n 'hour',\n 'is_leap_year',\n 'is_month_end',\n 'is_month_start',\n 'is_quarter_end',\n 'is_quarter_start',\n 'is_year_end',\n 'is_year_start',\n 'microsecond',\n 'microseconds',\n 'minute',\n 'month',\n 'month_name',\n 'nanosecond',\n 'nanoseconds',\n 'normalize',\n 'quarter',\n 'qyear',\n 'round',\n 'second',\n 'seconds',\n 'start_time',\n 'strftime',\n 'time',\n 'timetz',\n 'to_period',\n 'to_pydatetime',\n 'to_pytimedelta',\n 'to_timestamp',\n 'total_seconds',\n 'tz',\n 'tz_convert',\n 'tz_localize',\n 'week',\n 'weekday',\n 'weekofyear',\n 'year']"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# 当然，除了以上用法外，我们通过下面代码查看一下dt属性的完整列表：\n",
    "[i for i in dir(pd.Series.dt) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cat对象的使用\n",
    "- Series数据类型：Category\n",
    "\n",
    "在说cat对象的使用前，先说一下Category这个数据类型，它的作用很强大。虽然我们没有经常性的在内存中运行上g的数据，但是我们也总会遇到执行几行代码会等待很久的情况。使用Category数据的一个好处就是：可以很好的节省在时间和空间的消耗。下面我们通过几个实例来学习一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = pd.Series([\n",
    "    'periwinkle',\n",
    "    'mint green',\n",
    "    'burnt orange',\n",
    "    'periwinkle',\n",
    "    'burnt orange',\n",
    "    'rose',\n",
    "    'rose',\n",
    "    'mint green',\n",
    "    'rose',\n",
    "    'navy'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    59\n1    59\n2    61\n3    59\n4    61\n5    53\n6    53\n7    59\n8    53\n9    53\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "colors.apply(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们通过使用sys.getsizeof来显示内存占用的情况，数字代表字节数。还有另一种计算内容占用的方法：memory_usage()，后面会使用。\n",
    "\n",
    "现在我们将上面colors的不重复值映射为一组整数，然后再看一下占用的内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {v: k for k, v in enumerate(colors.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'periwinkle': 0, 'mint green': 1, 'burnt orange': 2, 'rose': 3, 'navy': 4}"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_int = colors.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0\n1    1\n2    2\n3    0\n4    2\n5    3\n6    3\n7    1\n8    3\n9    4\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    24\n1    28\n2    28\n3    24\n4    28\n5    28\n6    28\n7    28\n8    28\n9    28\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "as_int.apply(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：对于以上的整数值映射也可以使用更简单的pd.factorize()方法代替。\n",
    "\n",
    "我们发现上面所占用的内存是使用object类型时的一半。其实，这种情况就类似于Category data类型内部的原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`内存占用区别`：Categorical所占用的内存与Categorical分类的数量和数据的长度成正比，相反，object所占用的内存则是一个常数乘以数据的长度。\n",
    "\n",
    "下面是object内存使用和category内存使用的情况对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "650"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "colors.memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "495"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "colors.astype('category').memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面结果是使用object和Category两种情况下内存的占用情况。我们发现效果并没有我们想象中的那么好。但是注意Category内存是成比例的，如果数据集的数据量很大，但不重复分类（unique）值很少的情况下，`那么Category的内存占用可以节省达到10倍以上`，比如下面数据量增大的情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "manycolors = colors.repeat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20.0"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "len(manycolors)/manycolors.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6500"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "manycolors.memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "585"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "manycolors.astype('category').memory_usage(index=False, deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在数据量增加10倍以后，使用Category所占内容节省了10倍以上。\n",
    "\n",
    "`除了占用内存节省外，另一个额外的好处是计算效率有了很大的提升`。因为对于Category类型的Series，str字符的操作发生在.cat.categories的非重复值上，而并非原Series上的所有元素上。也就是说对于每个非重复值都只做一次操作，然后再向与非重复值同类的值映射过去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于Category的数据类型，可以使用accessor的cat对象，以及相应的属性和方法来操作Category数据。\n",
    "ccolors = colors.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['burnt orange', 'mint green', 'navy', 'periwinkle', 'rose'], dtype='object')"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "ccolors.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    0\n1    1\n2    2\n3    0\n4    2\n5    3\n6    3\n7    1\n8    3\n9    4\ndtype: int8"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# 实际上，对于开始的整数类型映射，可以先通过reorder_categories进行重新排序，然后再使用cat.codes来实现对整数的映射，来达到同样的效果。\n",
    "ccolors.cat.reorder_categories(mapper).cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtype类型是Numpy的int8（-127~128）。可以看出以上只需要一个单字节就可以在内存中包含所有的值。我们开始的做法默认使用了int64类型，然而通过pandas的使用可以很智能的将Category数据类型变为最小的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['add_categories',\n 'as_ordered',\n 'as_unordered',\n 'categories',\n 'codes',\n 'ordered',\n 'remove_categories',\n 'remove_unused_categories',\n 'rename_categories',\n 'reorder_categories',\n 'set_categories']"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# 让我们来看一下cat还有什么其它的属性和方法可以使用。下面cat的这些属性基本都是关于查看和操作Category数据类型的。\n",
    "[i for i in dir(ccolors.cat) if not i.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Cannot setitem on a Categorical with a new category, set the categories first",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-68e7590e313a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 但是Category数据的使用不是很灵活。例如，插入一个之前没有的值，首先需要将这个值添加到.categories的容器中，然后再添加值。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mccolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a new color'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# actually do the set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setitem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mcheck_setitem_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1797\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1798\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_add\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2047\u001b[0;31m                 \u001b[0;34m\"Cannot setitem on a Categorical with a new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2048\u001b[0m                 \u001b[0;34m\"category, set the categories first\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot setitem on a Categorical with a new category, set the categories first"
     ]
    }
   ],
   "source": [
    "# 但是Category数据的使用不是很灵活。例如，插入一个之前没有的值，首先需要将这个值添加到.categories的容器中，然后再添加值。\n",
    "ccolors.iloc[5] = 'a new color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccolors = ccolors.cat.add_categories(['a new color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccolors.iloc[5] = 'a new color'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0      periwinkle\n1      mint green\n2    burnt orange\n3      periwinkle\n4    burnt orange\n5     a new color\n6            rose\n7      mint green\n8            rose\n9            navy\ndtype: category\nCategories (6, object): [burnt orange, mint green, navy, periwinkle, rose, a new color]"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "ccolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想设置值或重塑数据，而非进行新的运算操作，那么Category类型不是那么有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从clipboard剪切板载入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们的数据存在excel表里，或者其它的IDE编辑器中的时候，我们想要通过pandas载入数据。我们通常的做法是先保存再载入，其实这样做起来十分繁琐。一个简单的方法就是使用pd.read_clipboard() 直接从电脑的剪切板缓存区中提取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就可以直接将结构数据转变为DataFrame或者Series了。excel表中数据是这样的：\n",
    "\n",
    "https://mmbiz.qpic.cn/mmbiz_png/NOM5HN2icXzw038ysxxs1WTdR6YiaWIrphmnYEeZe926FbAUgShmawKwwndrMA4wz5NVfSibxNXCgj2cB5nVq1ybw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用\"测试模块\"制作伪数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在pandas中，有一个测试模块可以帮助我们生成半真实（伪数据），并进行测试，它就是util.testing。下面同我们通过一个简单的例子看一下如何生成数据测试：\n",
    "import pandas.util.testing as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认的行和列\n",
    "tm.N, tm.K = 15, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   A         B         C         D\n2000-01-31  0.357440  0.266873  0.353728 -0.536561\n2000-02-29  0.377538 -0.480331 -0.433926 -0.886787\n2000-03-31  1.382338  0.300781 -0.498028  0.107101\n2000-04-30  1.175549 -0.179054  0.228771 -0.740890\n2000-05-31 -0.939276  1.183669 -0.650078 -0.075697",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2000-01-31</th>\n      <td>0.357440</td>\n      <td>0.266873</td>\n      <td>0.353728</td>\n      <td>-0.536561</td>\n    </tr>\n    <tr>\n      <th>2000-02-29</th>\n      <td>0.377538</td>\n      <td>-0.480331</td>\n      <td>-0.433926</td>\n      <td>-0.886787</td>\n    </tr>\n    <tr>\n      <th>2000-03-31</th>\n      <td>1.382338</td>\n      <td>0.300781</td>\n      <td>-0.498028</td>\n      <td>0.107101</td>\n    </tr>\n    <tr>\n      <th>2000-04-30</th>\n      <td>1.175549</td>\n      <td>-0.179054</td>\n      <td>0.228771</td>\n      <td>-0.740890</td>\n    </tr>\n    <tr>\n      <th>2000-05-31</th>\n      <td>-0.939276</td>\n      <td>1.183669</td>\n      <td>-0.650078</td>\n      <td>-0.075697</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "tm.makeTimeDataFrame(freq='M').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   A         B         C         D\nb8jgVbQbug -0.748504 -0.099509 -0.060078  0.035310\nOKCyyhkEvY  0.498427  0.798287 -0.169375 -1.487501\nRtcTWq0AMT -0.148212  0.507709 -0.089451 -0.716834\nvtdamOujY0 -0.348742  0.273927  1.551892 -0.054453\ntW49Zqe3lC  0.161808  0.839752  0.690683  1.536011",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>b8jgVbQbug</th>\n      <td>-0.748504</td>\n      <td>-0.099509</td>\n      <td>-0.060078</td>\n      <td>0.035310</td>\n    </tr>\n    <tr>\n      <th>OKCyyhkEvY</th>\n      <td>0.498427</td>\n      <td>0.798287</td>\n      <td>-0.169375</td>\n      <td>-1.487501</td>\n    </tr>\n    <tr>\n      <th>RtcTWq0AMT</th>\n      <td>-0.148212</td>\n      <td>0.507709</td>\n      <td>-0.089451</td>\n      <td>-0.716834</td>\n    </tr>\n    <tr>\n      <th>vtdamOujY0</th>\n      <td>-0.348742</td>\n      <td>0.273927</td>\n      <td>1.551892</td>\n      <td>-0.054453</td>\n    </tr>\n    <tr>\n      <th>tW49Zqe3lC</th>\n      <td>0.161808</td>\n      <td>0.839752</td>\n      <td>0.690683</td>\n      <td>1.536011</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "tm.makeDataFrame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面简单的使用了\n",
    "`makeTimeDataFrame` 和 `makeDataFrame` 分别生成了一组时间数据和DataFrame的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['makeBoolIndex',\n 'makeCategoricalIndex',\n 'makeCustomDataframe',\n 'makeCustomIndex',\n 'makeDataFrame',\n 'makeDateIndex',\n 'makeFloatIndex',\n 'makeFloatSeries',\n 'makeIntIndex',\n 'makeIntervalIndex',\n 'makeMissingCustomDataframe',\n 'makeMissingDataframe',\n 'makeMixedDataFrame',\n 'makeMultiIndex',\n 'makeObjectSeries',\n 'makePeriodFrame',\n 'makePeriodIndex',\n 'makePeriodSeries',\n 'makeRangeIndex',\n 'makeStringIndex',\n 'makeStringSeries',\n 'makeTimeDataFrame',\n 'makeTimeSeries',\n 'makeTimedeltaIndex',\n 'makeUIntIndex',\n 'makeUnicodeIndex']"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# 但这只是其中的两个用法，关于testing中的方法有大概30多个，如果你想全部了解，可以通过查看dir获得：\n",
    "[i for i in dir(tm) if i.startswith('make')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从列项中创建DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也许我们有的时候会遇到这样的情形（为了说明这种情情况，我使用了product进行交叉迭代的创建了一组关于时间的数据）：\n",
    "from itertools import product\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecols = ['year', 'month', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(product([2017, 2016],[1, 2], [1, 2, 3])), columns=datecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'] = np.random.randn(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    year  month  day      data\n0   2017      1    1 -1.715649\n1   2017      1    2 -1.157216\n2   2017      1    3 -0.026555\n3   2017      2    1 -0.134312\n4   2017      2    2 -1.853022\n5   2017      2    3 -0.152569\n6   2016      1    1  1.165075\n7   2016      1    2  0.387215\n8   2016      1    3 -0.923056\n9   2016      2    1 -2.010524\n10  2016      2    2  0.553357\n11  2016      2    3 -1.720923",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.715649</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-1.157216</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.026555</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.134312</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1.853022</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2017</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-0.152569</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.165075</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.387215</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2016</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.923056</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2016</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-2.010524</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2016</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.553357</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2016</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-1.720923</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "明显看到，列项中有`year，month，day`，它们分别在各个列中，而并非是一个完整日期。那么如何从这些列中将它们组合在一起并设置为新的index呢？\n",
    "\n",
    "通过to_datetime的使用，我们就可以直接将年月日组合为一个完整的日期，然后赋给索引。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df[datecols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            year  month  day      data\n2017-01-01  2017      1    1 -1.715649\n2017-01-02  2017      1    2 -1.157216\n2017-01-03  2017      1    3 -0.026555\n2017-02-01  2017      2    1 -0.134312\n2017-02-02  2017      2    2 -1.853022",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-01</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-1.715649</td>\n    </tr>\n    <tr>\n      <th>2017-01-02</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-1.157216</td>\n    </tr>\n    <tr>\n      <th>2017-01-03</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.026555</td>\n    </tr>\n    <tr>\n      <th>2017-02-01</th>\n      <td>2017</td>\n      <td>2</td>\n      <td>1</td>\n      <td>-0.134312</td>\n    </tr>\n    <tr>\n      <th>2017-02-02</th>\n      <td>2017</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1.853022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当然，你可以选择将原有的年月日列移除，只保留data数据列，然后squeeze转换为Series结构。\n",
    "df = df.drop(datecols, axis=1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2017-01-01   -1.715649\n2017-01-02   -1.157216\n2017-01-03   -0.026555\n2017-02-01   -0.134312\n2017-02-02   -1.853022\nName: data, dtype: float64"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('<M8[ns]')"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df.index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(12,)"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "df.index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}